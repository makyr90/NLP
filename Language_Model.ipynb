{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "from nltk.corpus import europarl_raw\n",
    "from nltk import ngrams\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from nltk.corpus import words\n",
    "\n",
    "alpha = 0.01 #alpha value is chosen using the validation set\n",
    "corpus = europarl_raw.english\n",
    "delta = 0.75\n",
    "P_cont_denom_bigrams = 0\n",
    "\n",
    "#split(sentences) into train-->60% validation-->20% and test-->20%\n",
    "train_init, test = train_test_split(corpus.sents(), train_size = 0.8,random_state=4542)\n",
    "train, validation = train_test_split(train_init, train_size = 0.75,random_state=4572)\n",
    "\n",
    "def getCount(countdict,key):   \n",
    "#Helper function that returns # of uni/bi/tri -grams(key) occurencies in corpus.\n",
    "#If there are not such occurencies in corpus returns 0\n",
    "    try:\n",
    "        return countdict[key]\n",
    "    except KeyError:\n",
    "        return 0  \n",
    "    \n",
    "cnt = Counter()\n",
    "for word in [item for sublist in train for item in sublist]:\n",
    "    cnt[word] += 1\n",
    "\n",
    "#Remove rare words \n",
    "unigrams = { k:v for k, v in cnt.items() if v >= 10}\n",
    "unigrams['<s>'] = 1\n",
    "unigrams_size = sum(v for v in unigrams.values())\n",
    "V = len(unigrams)\n",
    "\n",
    "\n",
    "bigrams =  (ngram for sent in train for ngram in ngrams(sent, 2,\n",
    "    pad_left=True, pad_right=True, pad_symbol='<s>'))\n",
    "\n",
    "cnt2 = Counter()\n",
    "for bigram in bigrams:\n",
    "    cnt2[bigram] += 1\n",
    "\n",
    "\n",
    "    \n",
    "#remove bigrams containing rare words\n",
    "bigrams_final = { k:v for k, v in cnt2.items() if ((k[0] in unigrams.keys()) and(k[1] in unigrams.keys())) }\n",
    "bigrams_size = sum(v for v in bigrams_final.values())\n",
    "\n",
    "#Auxiliary data structure for bigrams that  used in order to improve Knesser-Ney performance\n",
    "bigrams_KN ={}\n",
    "for k, v in bigrams_final.items():\n",
    "    bigrams_KN[k[0]] = {}\n",
    "for k, v in bigrams_final.items():\n",
    "    bigrams_KN[k[0]][k[1]] = v\n",
    "\n",
    "#Auxiliary data structure for bigrams that used in order to improve Knesser-Ney performance  \n",
    "bigrams_KN_reverse ={}\n",
    "for k, v in bigrams_final.items():\n",
    "    bigrams_KN_reverse[k[1]] = {}\n",
    "for k, v in bigrams_final.items():\n",
    "    bigrams_KN_reverse[k[1]][k[0]] = v\n",
    "\n",
    "#compute P(continuation) denominator for bigrams\n",
    "wordsNum = []\n",
    "for k,v in bigrams_final.items():\n",
    "    wordsNum.append(k[0])\n",
    "P_cont_denom_bigrams = len(set(wordsNum))\n",
    "trigrams = (ngram for sent in train for ngram in ngrams(sent, 3,\n",
    "            pad_left=True, pad_right=True, pad_symbol='<s>'))\n",
    "\n",
    "\n",
    "cnt3 = Counter()\n",
    "for trigram in trigrams:\n",
    "    cnt3[trigram] += 1\n",
    "\n",
    "#remove trigrams containing rare words\n",
    "trigrams_final = { k:v for k, v in cnt3.items() if ((k[0] in unigrams.keys())\n",
    "    and(k[1] in unigrams.keys()) and(k[2] in unigrams.keys())) }\n",
    "trigrams_size = sum(v for v in trigrams_final.values())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def unigram_logprob_ls(unigram):\n",
    "# laplace smoothing\n",
    "    global alpha\n",
    "    return math.log2(((getCount(unigrams,unigram))+alpha) / (unigrams_size+(alpha*V)) )\n",
    "\n",
    "def bigram_logprob_ls(bigram):\n",
    "# laplace smoothing\n",
    "    global alpha\n",
    "    return math.log2(((getCount(bigrams_final,bigram))+alpha ) / ((getCount(unigrams,(bigram[0])))+(alpha*V))) \n",
    "    \n",
    "def bigram_logprob_Mod_KN(bigram):\n",
    "# Modified Knesser ney \n",
    "    global delta\n",
    "    try:\n",
    "        return math.log2(((max((getCount(bigrams_final,bigram) -delta),0)) / getCount(unigrams,(bigram[0]))) \n",
    "                     +((bigram_Mod_KN_lamda(bigram[0])) * bigram_Mod_KN_Pcont(bigram[1])))\n",
    "    \n",
    "    except (ZeroDivisionError,ValueError):\n",
    "        # return 0 if both bigram does not exist and P(continuation) is  zero\n",
    "        return 0\n",
    "    \n",
    "\n",
    "    \n",
    "def bigram_Mod_KN_lamda(word):\n",
    "#Compute Modified Knesser ney  interpolation term(lamda)\n",
    "    global delta\n",
    "    # Compute The number of word types that can follow word\n",
    "    try:\n",
    "        times = len(bigrams_KN[word])\n",
    "    except KeyError:\n",
    "        return 0\n",
    "    lamda = (delta/getCount(unigrams,word)) * times\n",
    "    return lamda\n",
    "\n",
    "def bigram_Mod_KN_Pcont(word):\n",
    "#Compute P continuation\n",
    "    global P_cont_denom_bigrams\n",
    "    #Count distinct vocabulary words seen to proceede word\n",
    "    try:\n",
    "        count = len(bigrams_KN_reverse[word])\n",
    "    except KeyError:\n",
    "        return 0\n",
    "    return count/P_cont_denom_bigrams\n",
    "    \n",
    "\n",
    "def trigram_logprob_ls(trigram):\n",
    "# laplace smoothing\n",
    "    global alpha\n",
    "    return math.log2(((getCount(trigrams_final,trigram)) +alpha ) /\n",
    "                     ((getCount(bigrams_final,(trigram[0],trigram[1])))+(alpha*V)))   \n",
    "\n",
    "def logprob_sentence_bigram(sentence):\n",
    "    sumprob = 0\n",
    "    for i in range(len(sentence)-1):\n",
    "        sumprob += bigram_logprob_ls((sentence[i],sentence[i+1]))\n",
    "    return sumprob\n",
    "\n",
    "def logprob_sentence_bigram_Mod_KN(sentence):\n",
    "    sumprob = 0\n",
    "    for i in range(len(sentence)-1):\n",
    "        sumprob += bigram_logprob_Mod_KN((sentence[i],sentence[i+1]))\n",
    "    return sumprob       \n",
    "    \n",
    "def logprob_sentence_trigram(sentence):\n",
    "    sumprob = 0\n",
    "    for i in range(len(sentence)-2):\n",
    "        sumprob += trigram_logprob_ls((sentence[i],sentence[i+1],sentence[i+2]))\n",
    "    return sumprob\n",
    "\n",
    "\n",
    "    \n",
    "def bigram_model_perplexity(corpus):\n",
    "    #Compute cross entropy and perplexity of our bigram model\n",
    "    sumprob = 0\n",
    "    bigram_count = 0\n",
    "    for sentence in corpus:\n",
    "        sentence = ['<s>'] + sentence + ['<s>'] \n",
    "        bigram_count += (len(sentence) -1)\n",
    "        sumprob += logprob_sentence_bigram(sentence)\n",
    "    cross_entropy = -sumprob/bigram_count\n",
    "    perpl = math.pow(2,cross_entropy)\n",
    "    return cross_entropy,perpl\n",
    "\n",
    "\n",
    "def bigram_model_perplexity_Mod_KN(corpus):\n",
    "    #Compute cross entropy and perplexity of our bigram model with Modified Knesser-Ney Smoothing\n",
    "    sumprob = 0\n",
    "    bigram_count = 0\n",
    "    for sentence in corpus:\n",
    "        sentence = ['<s>'] + sentence + ['<s>'] \n",
    "        bigram_count += (len(sentence) -1)\n",
    "        sumprob += logprob_sentence_bigram_Mod_KN(sentence)\n",
    "    cross_entropy = -sumprob/bigram_count\n",
    "    perpl = math.pow(2,cross_entropy)\n",
    "    return cross_entropy,perpl\n",
    "\n",
    "def trigram_model_perplexity(corpus):\n",
    "    #Compute cross entropy and perplexity of our trigram model\n",
    "    sumprob = 0\n",
    "    trigram_count = 0\n",
    "    for sentence in corpus:\n",
    "        sentence = ['<s>','<s>'] + sentence + ['<s>','<s>'] \n",
    "        trigram_count += (len(sentence) -2)\n",
    "        sumprob += logprob_sentence_trigram(sentence)\n",
    "    cross_entropy = -sumprob/trigram_count\n",
    "    perpl = math.pow(2,cross_entropy)\n",
    "    return cross_entropy,perpl\n",
    "    \n",
    "def score_sentence_vs_random(corpus):\n",
    "    sent= random.choice(corpus)\n",
    "    sent = ['<s>','<s>'] + sent + ['<s>','<s>'] \n",
    "    score_sent = logprob_sentence_trigram(sent)\n",
    "    print(sent,\"score:\",score_sent)\n",
    "    random_sent = []\n",
    "    for i in range(len(sent)-4):\n",
    "        random_sent.append(random.choice(words.words()))\n",
    "    random_sent =['<s>','<s>']+ random_sent + ['<s>','<s>']\n",
    "    score_random_sent = logprob_sentence_trigram(random_sent)\n",
    "    print(random_sent,\"score:\",score_random_sent)\n",
    "\n",
    "def predict_next_word(sentence):\n",
    "    #predict next word based on most frequent relevant trigrams/ bigrams\n",
    "    suggestions = []\n",
    "    if (len(sentence) >= 2):\n",
    "        trigrams = { k:v for k, v in trigrams_final.items() if ((k[0] == sentence[-2])\n",
    "            and(k[1] == sentence[-1]))  }\n",
    "        if (len(trigrams)>0):\n",
    "            sortdict = [(k, trigrams[k]) for k in sorted(trigrams, key=trigrams.get, reverse=True)]\n",
    "            for k,v in sortdict[:3]:\n",
    "                suggestions.append(k[2])\n",
    "            \n",
    "    else:\n",
    "        bigrams = { k:v for k, v in bigrams_final.items() if ((k[0] == sentence[-1])) }\n",
    "        if (len(bigrams)>0):\n",
    "            sortdict = [(k, bigrams[k]) for k in sorted(bigrams, key=bigrams.get, reverse=True)]\n",
    "            for k,v in sortdict[:3]:\n",
    "                suggestions.append(k[1])\n",
    "    \n",
    "    \n",
    "    return suggestions\n",
    "       \n",
    "def bigram_trigram_interpolation_prob(trigram,lamda1,lamda2):\n",
    "    #interpolate bigrams and trigrams\n",
    "    assert(lamda1+lamda2==1.0),\"error interpolation coefs must sum to 1!\"\n",
    "    return ((lamda1*trigram_logprob_ls((trigram[0],trigram[1],trigram[2]))) + \n",
    "             (lamda2*bigram_logprob_ls((trigram[1],trigram[2]))))\n",
    "\n",
    "def interpolated_sentence(sentence,lamda1,lamda2):\n",
    "    #propability of sentence using the interpolation of the bigram/trigram models\n",
    "    sumprob = 0\n",
    "    for i in range(len(sentence)-2):\n",
    "        sumprob += bigram_trigram_interpolation_prob((sentence[i],sentence[i+1],sentence[i+2]),lamda1,lamda2)\n",
    "    return sumprob\n",
    "\n",
    "def interpolated_model_perplexity(corpus,lamda1,lamda2):\n",
    "    #Compute cross entropy and perplexity of our trigram model\n",
    "    sumprob = 0\n",
    "    trigram_count = 0\n",
    "    for sentence in corpus:\n",
    "        sentence = ['<s>','<s>'] + sentence + ['<s>','<s>'] \n",
    "        trigram_count += (len(sentence) -2)\n",
    "        sumprob += interpolated_sentence(sentence,lamda1,lamda2)\n",
    "    cross_entropy = -sumprob/trigram_count\n",
    "    perpl = math.pow(2,cross_entropy)\n",
    "    return perpl\n",
    "\n",
    "\n",
    "# for i in range(0, 101, 1):\n",
    "#     lamda1 = i/100\n",
    "#     lamda2 = 1-lamda1\n",
    "#     print(\"lamda1: \",lamda1,\" lamda2: \",lamda2,\" perplexity--> \"\n",
    "#           ,interpolated_model_perplexity(validation,lamda1,lamda2))\n",
    "#Best model where lamda1=0 and lamda2 =1\n",
    "    \n",
    "\n",
    "\n",
    "#Use validation data to tune alpha parameter\n",
    "# for i in range(1,101,1):\n",
    "#     alpha = i/1000\n",
    "#     print(\"alpha:\", alpha)\n",
    "#     print(bigram_model_perplexity(validation))\n",
    "\n",
    "#     print(trigram_model_perplexity(validation))\n",
    "\n",
    "\n",
    "print(bigram_model_perplexity_Mod_KN(train))\n",
    "print(bigram_model_perplexity(train))\n",
    "print(trigram_model_perplexity(train))\n",
    "print(bigram_model_perplexity_Mod_KN(test))\n",
    "print(bigram_model_perplexity(test))\n",
    "print(trigram_model_perplexity(test))\n",
    "\n",
    "score_sentence_vs_random(test)\n",
    "print(predict_next_word([\"treaty\"]))\n",
    "\n",
    "#Results @ TEST(Cross Entropy, perplexity)\n",
    "# (3.74168230957505, 13.376996376432324) --> bigram Knesser-Kney \n",
    "# (7.3882090675850725, 167.52226781094902) --> bigram laplace smoothing\n",
    "# (8.203994032606882, 294.8820167238192) --> --> trigram laplace smoothing\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
