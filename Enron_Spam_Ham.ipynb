{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from nltk import ngrams\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Data are taken from http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/index.html (pre-processed form)\n",
    "\n",
    "HAM_DIRECTORY = \"/home/manolis/Desktop/Enron/ham\"\n",
    "SPAM_DIRECTORY = \"/home/manolis/Desktop/Enron/spam\"\n",
    "\n",
    "def read_files(directory,class_label):\n",
    "    data = []\n",
    "    index = []\n",
    "    for filename in os.listdir(directory):\n",
    "        email_content = \"\"\n",
    "        with open(directory+\"/\"+filename, 'r',encoding='utf-8', errors='ignore') as email:\n",
    "            for line in email:\n",
    "                line = line.strip('\\n')\n",
    "                line = line.strip('\\t')\n",
    "                email_content+= line\n",
    "\n",
    "        email.close()\n",
    "        data.append({'text': email_content, 'label': class_label})\n",
    "        index.append(filename)\n",
    "    return data,index\n",
    "\n",
    "def count_ngrams(ngrams):\n",
    "    cnt = Counter()\n",
    "    for ngram in ngrams:\n",
    "        cnt[ngram] += 1\n",
    "    return cnt\n",
    "\n",
    "Ham_data,index_hamdata = read_files(HAM_DIRECTORY,\"Ham\")\n",
    "Spam_data,index_spamdata = read_files(SPAM_DIRECTORY,\"Spam\")\n",
    "data_frame = DataFrame(Ham_data,index =index_hamdata)\n",
    "data_frame = data_frame.append(DataFrame(Spam_data,index =index_spamdata))\n",
    "#shufle dataframe\n",
    "data_frame = shuffle(data_frame,random_state = 456987)\n",
    "\n",
    "train, test = train_test_split(data_frame, train_size = 0.8,random_state=4542)\n",
    "\n",
    "\n",
    "unigrams =  (ngram for sent in train.ix[:,1] for ngram in ngrams(sent.split(),1))\n",
    "unigrams_final = { k:v for k, v in count_ngrams(unigrams).items() if v>100}\n",
    "\n",
    "\n",
    "bigrams =  (ngram for sent in train.ix[:,1] for ngram in ngrams(sent.split(),2))\n",
    "bigrams_final = { k:v for k, v in count_ngrams(bigrams).items() if v>100}\n",
    "\n",
    "\n",
    "IDF = {}\n",
    "for k in bigrams_final.keys():\n",
    "    IDF[k]=0\n",
    "\n",
    "for k in unigrams_final.keys():\n",
    "    IDF[k[0]]=0\n",
    "\n",
    "\n",
    "for idx in range(len(train)):\n",
    "    grams_1 = ngrams(train['text'][idx].split(),1)\n",
    "    grams_1set = []\n",
    "    for gram in grams_1:\n",
    "        if (gram not in grams_1set):\n",
    "            try:\n",
    "                IDF[gram[0]]+=1\n",
    "                grams_1set.append(gram)  \n",
    "            except KeyError:\n",
    "                 continue\n",
    "    grams_2 = ngrams(train['text'][idx].split(),2)\n",
    "    grams_2set = []\n",
    "    for gram in grams_2:\n",
    "        if (gram not in grams_2set):\n",
    "            try:\n",
    "                IDF[gram]+=1\n",
    "                grams_2set.append(gram)  \n",
    "            except KeyError:\n",
    "                 continue\n",
    "           \n",
    "    \n",
    "\n",
    "\n",
    "for k,v in IDF.items():\n",
    "    IDF[k] = math.log(len(train)/(1+ v))\n",
    "\n",
    "tfIDFvector_train = {}\n",
    "for key in IDF.keys():\n",
    "    tfIDFvector_train[key] = np.zeros(len(train))\n",
    "    \n",
    "\n",
    "for idx in range(len(train)):\n",
    "    grams_1 = ngrams(train['text'][idx].split(),1)\n",
    "    grams_1_counter = count_ngrams(grams_1)\n",
    "    for k,v in grams_1_counter.items():\n",
    "        try:\n",
    "            tfIDFvector_train[k][idx] = v*IDF[k]\n",
    "        except KeyError:\n",
    "            continue\n",
    "    grams_2 = ngrams(train['text'][idx].split(),2)\n",
    "    grams_2_counter = count_ngrams(grams_2)\n",
    "    for k,v in grams_2_counter.items():\n",
    "        try:\n",
    "            tfIDFvector_train[k][idx] = v*IDF[k]\n",
    "        except KeyError:\n",
    "            continue\n",
    "            \n",
    "tfidf_dataframe = DataFrame(tfIDFvector_train)\n",
    "tfidf_dataframe.apply(pd.to_numeric)\n",
    "tfidf_dataframe = tfidf_dataframe.set_index(train.index)\n",
    "tfidf_dataframe['label'] = train['label'].astype(str)\n",
    "tfidf_dataframe.index= range(len(tfidf_dataframe))\n",
    "tfidf_dataframe['label'] = tfidf_dataframe['label'].astype('category')\n",
    "\n",
    "\n",
    "tfIDFvector_test= {}\n",
    "for key in IDF.keys():\n",
    "    tfIDFvector_test[key] = np.zeros(len(test))\n",
    "    \n",
    "\n",
    "for idx in range(len(test)):\n",
    "    grams_1 = ngrams(test['text'][idx].split(),1)\n",
    "    grams_1_counter = count_ngrams(grams_1)\n",
    "    for k,v in grams_1_counter.items():\n",
    "        try:\n",
    "            tfIDFvector_test[k][idx] = v*IDF[k]\n",
    "        except KeyError:\n",
    "            continue\n",
    "    grams_2 = ngrams(test['text'][idx].split(),2)\n",
    "    grams_2_counter = count_ngrams(grams_2)\n",
    "    for k,v in grams_2_counter.items():\n",
    "        try:\n",
    "            tfIDFvector_test[k][idx] = v*IDF[k]\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "tfidf_dataframe_test = DataFrame(tfIDFvector_test)\n",
    "tfidf_dataframe_test.apply(pd.to_numeric)\n",
    "tfidf_dataframe_test = tfidf_dataframe_test.set_index(test.index)\n",
    "tfidf_dataframe_test['label'] = test['label'].astype(str)\n",
    "tfidf_dataframe_test.index= range(len(tfidf_dataframe_test))\n",
    "tfidf_dataframe_test['label'] = tfidf_dataframe_test['label'].astype('category')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data = tfidf_dataframe.ix[:, tfidf_dataframe.columns != 'label']\n",
    "train_labels = Series(tfidf_dataframe['label'])\n",
    "test_data = tfidf_dataframe_test.ix[:, tfidf_dataframe_test.columns != 'label']\n",
    "test_labels = Series(tfidf_dataframe_test['label'])\n",
    "\n",
    "#Check that train and test sets has the same columns and the same order of columns\n",
    "cols = train_data.columns.tolist()\n",
    "cols2 = test_data.columns.tolist()\n",
    "cols ==cols2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Baseline classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "base = DummyClassifier(strategy='most_frequent')\n",
    "base.fit(train_data, train_labels)\n",
    "predictions = base.predict(train_data)\n",
    "score = f1_score(train_labels, predictions,pos_label='Spam')\n",
    "print(\"train score:\",score)\n",
    "\n",
    "predictions_test = base.predict(test_data)\n",
    "score = f1_score(test_labels, predictions_test,pos_label='Spam')\n",
    "print(\"test score:\",score)\n",
    "print()\n",
    "print(\"test data confusion matrix\")\n",
    "pd.crosstab(test_labels, predictions_test, rownames=['True'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_data, train_labels)\n",
    "predictions = clf.predict(train_data)\n",
    "score = f1_score(train_labels, predictions,pos_label='Spam')\n",
    "print(\"train score:\",score)\n",
    "\n",
    "predictions_test = clf.predict(test_data)\n",
    "score = f1_score(test_labels, predictions_test,pos_label='Spam')\n",
    "print(\"test score:\",score)\n",
    "print()\n",
    "print(\"test data confusion matrix\")\n",
    "pd.crosstab(test_labels, predictions_test, rownames=['True'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(train_data, train_labels)\n",
    "predictions = lr.predict(train_data)\n",
    "score = f1_score(train_labels, predictions,pos_label='Spam')\n",
    "print(\"train score:\",score)\n",
    "\n",
    "predictions_test = lr.predict(test_data)\n",
    "score = f1_score(test_labels, predictions_test,pos_label='Spam')\n",
    "print(\"test score:\",score)\n",
    "print()\n",
    "print(\"test data confusion matrix\")\n",
    "pd.crosstab(test_labels, predictions_test, rownames=['True'], colnames=['Predicted'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reduce dimensionality in order to use svm and k-nn algorithms\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "train_data.shape\n",
    "clf = ExtraTreesClassifier()\n",
    "rdim = clf.fit(train_data, train_labels)\n",
    "model = SelectFromModel(rdim, prefit=True)\n",
    "train_data_new = model.transform(train_data)\n",
    "test_data_new = model.transform(test_data)\n",
    "print(test_data.shape)\n",
    "print(test_data_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "clf_svm.fit(train_data_new, train_labels)\n",
    "\n",
    "predictions = clf_svm.predict(train_data_new)\n",
    "score = f1_score(train_labels, predictions,pos_label='Spam')\n",
    "print(\"train score:\",score)\n",
    "\n",
    "predictions_test = clf_svm.predict(test_data_new)\n",
    "score = f1_score(test_labels, predictions_test,pos_label='Spam')\n",
    "print(\"test score:\",score)\n",
    "print()\n",
    "print(\"test data confusion matrix\")\n",
    "pd.crosstab(test_labels, predictions_test, rownames=['True'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "neigh.fit(train_data_new,train_labels)\n",
    "predictions = neigh.predict(train_data_new)\n",
    "predictions_test = neigh.predict(test_data_new)\n",
    "\n",
    "score = f1_score(train_labels, predictions,pos_label='Spam')\n",
    "print(\"train score:\",score)\n",
    "\n",
    "score = f1_score(test_labels, predictions_test,pos_label='Spam')\n",
    "print(\"test score:\",score)\n",
    "print()\n",
    "print(\"test data confusion matrix\")\n",
    "pd.crosstab(test_labels, predictions_test, rownames=['True'], colnames=['Predicted'])\n",
    "\n",
    "\n",
    "# train score: 0.918331914894\n",
    "# test score: 0.888389314996\n",
    "\n",
    "# test data confusion matrix\n",
    "\n",
    "# Out[36]:\n",
    "# Predicted \tHam \tSpam\n",
    "# True \t\t\n",
    "# Ham \t2538 \t755\n",
    "# Spam \t89 \t3359"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "   \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "X, y = train_data.as_matrix(),train_labels.as_matrix()\n",
    "\n",
    "title = \"Learning Curves (Naive Bayes)\"\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "estimator = MultinomialNB()\n",
    "plot_learning_curve(estimator, title, X, y, ylim=(0.7, 1.01), cv=cv, n_jobs=2)\n",
    "\n",
    "title = \"Learning Curves (Logistic Regression)\"\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "estimator = LogisticRegression()\n",
    "plot_learning_curve(estimator, title, X, y, (0.7, 1.01), cv=cv, n_jobs=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "#disable warnings for large float numbers of estimated probabilities\n",
    "np.seterr(all='ignore')\n",
    "\n",
    "y_test= label_binarize(test_labels.as_matrix(), classes=['Ham','Spam'])\n",
    "\n",
    "estimators = {'Logistic Regression':LogisticRegression(), 'Naive Bayes ':MultinomialNB()}\n",
    "\n",
    "for (name,estimator) in estimators.items():\n",
    "    \n",
    "    model =estimator\n",
    "    model.fit(train_data_new,train_labels)\n",
    "    pred = model.predict_proba(test_data_new)\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, pred[:,1])\n",
    "    area = auc(recall, precision)\n",
    "\n",
    "    plt.plot(recall, precision, label='Precision-Recall curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall %s: AUC=%0.2f' % (name,area))\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
