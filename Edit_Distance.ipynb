{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def DP_table(word1,word2):\n",
    "    \n",
    "    # Construct DP table,in order to compute Levenstein distance\n",
    "    # Use a list of lists as data structure for DP table\n",
    "    \n",
    "    dist_table = []\n",
    "    word2_list = list(word2)\n",
    "    for i in range(len(word2)+2):\n",
    "        table_row = []\n",
    "        if (i == 0):\n",
    "            table_row.append(\"\")\n",
    "            table_row.append(\"#\")\n",
    "            table_row.extend(list(word1))\n",
    "        elif (i == 1):\n",
    "            table_row.append(\"#\")\n",
    "            table_row.extend(range(len(word1)+1))\n",
    "        else:\n",
    "            table_row.append(word2_list[i-2])\n",
    "            table_row.append(i-1)\n",
    "            table_row.extend([0]*len(word1))\n",
    "        dist_table.append(table_row)\n",
    "   \n",
    "    return(dist_table)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "def compute_distance(word1,word2):\n",
    "    \n",
    "    #fill row by row the DP table with the calculated Levenstein distance\n",
    "    #according to the associated cost below\n",
    "    \n",
    "    insertion = 1\n",
    "    deletion = 1\n",
    "    replace = 2\n",
    "    \n",
    "    #Construct & initialize DP table\n",
    "    dp_table = DP_table(word1,word2)\n",
    "    for i in range(2,(len(word2)+2)):\n",
    "        for j in range(2,(len(word1)+2)):\n",
    "            if dp_table[0][j] ==  dp_table[i][0]:\n",
    "                dp_table[i][j] = min((dp_table[i][j-1]+insertion),(dp_table[i-1][j]+deletion),(dp_table[i-1][j-1]))\n",
    "            else:\n",
    "                dp_table[i][j] = min((dp_table[i][j-1]+insertion),(dp_table[i-1][j]+deletion),(dp_table[i-1][j-1]+replace))\n",
    "            \n",
    "   \n",
    "    return dp_table\n",
    "    \n",
    "\n",
    "    \n",
    "pd.DataFrame(compute_distance(\"παιζετε\",\"πεζοιται\"))\n",
    "#Note that we have different results when also include words intonation(greek)\n",
    "#e.g compute_distance(\"παίζετε\",\"πέζοιται\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extend code above to accept as input a word w, a vocabulary V ,\n",
    "#and a maximum distance d, and return the words of V whose Levenshtein\n",
    "#distance to w is up to d\n",
    "\n",
    "from nltk.corpus import words\n",
    "from pqdict import pqdict\n",
    "\n",
    "def comp_closest_words(word,vocabulary,levenstein_dist_thres,verbose = False):\n",
    "    count = 0\n",
    "    pq = pqdict()\n",
    "    for voc_word in vocabulary:\n",
    "        dist = compute_distance(word,voc_word)\n",
    "        if (dist[-1][-1] <= levenstein_dist_thres):\n",
    "            pq.update({voc_word:dist[-1][-1]})\n",
    "           \n",
    "        if (((count%10000)==0) and verbose):\n",
    "            print(\"Iteration:\",count)\n",
    "        count +=1\n",
    "    return pq\n",
    "\n",
    "#Use an english vocabulary from nltk library, to test the comp_closest_words function \n",
    "voc = words.words()\n",
    "result = comp_closest_words(\"parlamen\",voc,2,True)\n",
    "for key, value in result.items() :\n",
    "    print(key, value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
